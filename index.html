<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="ROMA: Real-time Omni-Multimodal Assistant with Interactive Streaming Understanding">
  <meta name="keywords" content="ROMA, Omni-multimodal, Streaming, VideoLLM, ACL">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ROMA: Real-time Omni-Multimodal Assistant</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  
  <style>
    body { font-family: 'Noto Sans', sans-serif; }
    .title.is-1 { font-family: 'Google Sans', sans-serif; }
    .publication-title { font-size: 2.5rem; font-weight: 700; margin-bottom: 1rem; }
    .publication-authors { font-size: 1.2rem; color: #4a4a4a; margin-bottom: 1.5rem; }
    .publication-links { display: flex; justify-content: center; gap: 10px; margin-top: 1rem; flex-wrap: wrap; }
    .abstract-text { font-size: 1.1rem; line-height: 1.6; text-align: justify; }
    .section-title { margin-top: 3rem; margin-bottom: 1.5rem; }
    .hero-body { padding-bottom: 1rem; }
    .teaser-caption { font-size: 0.9rem; color: #666; margin-top: 0.5rem; }
    .bibtex-box { background-color: #f5f5f5; padding: 15px; border-radius: 5px; overflow-x: auto; font-family: monospace; font-size: 0.9rem; }
    
    /* 视频容器样式 - 16:9 */
    .publication-video {
      position: relative;
      padding-bottom: 56.25%;
      height: 0;
      overflow: hidden;
      max-width: 100%;
      border-radius: 10px;
      box-shadow: 0 4px 8px rgba(0,0,0,0.1);
      margin-top: 2rem;
    }
    .publication-video iframe {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
    }

    /* 图片通用样式 */
    .result-image {
      border-radius: 10px;
      box-shadow: 0 4px 8px rgba(0,0,0,0.1);
      margin-bottom: 10px;
    }
    
    /* 分隔线 */
    hr {
      margin: 3rem 0;
      background-color: #f1f1f1;
    }
    
    /* 表格标题 */
    .table-caption {
      font-size: 0.95rem; 
      color: #4a4a4a; 
      margin-top: 5px; 
      margin-bottom: 25px;
    }
  </style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">ROMA: Real-time Omni-Multimodal Assistant<br>with Interactive Streaming Understanding</h1>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block"><strong>Anonymous Authors</strong><sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
             <span class="author-block"><sup>1</sup>ACL Submission</span>
          </div>

          <div class="publication-links">
            <span class="link-block">
              <a href="#" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                <span>Paper</span>
              </a>
            </span>
            <span class="link-block">
              <a class="external-link button is-normal is-rounded is-light" style="pointer-events: none; opacity: 0.6;">
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Code (Coming Soon)</span>
              </a>
            </span>
            <span class="link-block">
              <a class="external-link button is-normal is-rounded is-light" style="pointer-events: none; opacity: 0.6;">
                <span class="icon"><i class="far fa-images"></i></span>
                <span>Dataset (Coming Soon)</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" style="padding-top: 0;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <img src="./static/teaser.png" 
             alt="ROMA Streaming Capabilities" 
             class="result-image"
             style="max-height: 450px; width: auto;">
             
        <h2 class="subtitle has-text-justified teaser-caption">
          <strong>Figure 1: ROMA's streaming understanding capabilities.</strong> 
          It supports proactive tasks, including event alerts and narration, alongside reactive question answering.
        </h2>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified abstract-text">
            <p>
              Recent Omni-multimodal Large Language Models show promise in unified audio, vision, and text modeling. However, streaming audio-video understanding remains challenging, as existing approaches suffer from disjointed capabilities: they typically exhibit incomplete modality support or lack autonomous proactive monitoring.
            </p>
            <p>
              To address this, we present ROMA, <strong>a real-time omni-multimodal assistant for unified reactive and proactive interaction.</strong> ROMA processes continuous inputs as synchronized <em>multimodal units</em>, aligning dense audio with discrete video frames to handle granularity mismatches. For online decision-making, we introduce a lightweight <em>speak head</em> that decouples response initiation from generation to ensure precise triggering without task conflict.
            </p>
            <p>
              We train ROMA with a curated streaming dataset and a two-stage curriculum that progressively optimizes for streaming format adaptation and proactive responsiveness. To standardize the fragmented evaluation landscape, we reorganize diverse benchmarks into a unified suite covering both proactive (alert, narration) and reactive (QA) settings. Extensive experiments across 12 benchmarks demonstrate ROMA achieves state-of-the-art performance on proactive tasks while competitive in reactive settings, validating its robustness in unified real-time omni-multimodal understanding.
            </p>
          </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Demo Video</h2>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/YOUR_VIDEO_ID?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Methodology</h2>
        <div class="content has-text-justified">
          <p>
            ROMA unifies reactive answering and proactive timing over continuous inputs. The architecture utilizes chunked <strong>Time-aligned Multimodal ROPE (TMROPE)</strong> and a dedicated <strong>Speak Head</strong> for alignment and timing control.
          </p>
          <div class="has-text-centered" style="margin: 2rem 0;">
            <img src="./static/architecture.png" 
                 alt="ROMA Architecture" 
                 class="result-image" 
                 style="width: 100%;">
            <p class="teaser-caption has-text-centered"><strong>Figure 2: Model Architecture.</strong></p>
          </div>
          
          <p><strong>Key Innovations:</strong></p>
          <ul>
            <li><strong>Multimodal Units:</strong> We segment continuous audio into one-second intervals synchronized with video frames.</li>
            <li><strong>Speak Head:</strong> A lightweight module parallel to the LM head that explicitly predicts response timing (binary decision).</li>
            <li><strong>Two-Stage Training:</strong> A curriculum that first adapts the model to streaming formats and then optimizes for proactive responsiveness.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">ROMA Streaming Dataset</h2>
    <div class="columns is-centered">
      <div class="column is-full-width">
         <div class="content has-text-centered">
          <p class="has-text-justified">
            We constructed a comprehensive streaming dataset covering Proactive (Alert, Narration) and Reactive (QA) tasks, totaling over 676K samples.
          </p>
          <img src="./static/dataset.png" 
               alt="Dataset Statistics" 
               class="result-image" 
               style="width: 100%;">
          <p class="teaser-caption has-text-centered"><strong>Figure 4: Dataset Overview.</strong></p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Qualitative Analysis</h2>
    
    <div class="content">
      <h3 class="title is-4">Proactive Interaction: Event Alerts</h3>
      <p>ROMA can accurately detect transient events and recurrences in real-time streams.</p>
      
      <div class="columns is-centered">
        <div class="column is-full-width">
          <img src="./static/case_proactive.png" alt="Single Alert Case" class="result-image" style="width: 100%;">
          <p class="teaser-caption has-text-centered"><strong>Figure: Single Alert Case.</strong> ROMA triggers precise alerts for one-time events.</p>
        </div>
      </div>
      <div class="columns is-centered">
        <div class="column is-full-width">
          <img src="./static/case_proactive_multi.png" alt="Multi Alert Case" class="result-image" style="width: 100%;">
          <p class="teaser-caption has-text-centered"><strong>Figure: Recurring Alert Case.</strong> ROMA handles recurring events effectively.</p>
        </div>
      </div>
    </div>

    <div class="content">
      <h3 class="title is-4">Proactive Interaction: Real-Time Narration</h3>
      <p>Compared with baseline VideoLLMs, ROMA provides succinct and time-aligned summaries of events without accessing future context.</p>
      <div class="columns is-centered">
        <div class="column is-full-width">
          <img src="./static/case_narration.png" alt="Narration Case Study" class="result-image" style="width: 100%;">
          <p class="teaser-caption has-text-centered"><strong>Figure: Narration Case Study.</strong> Comparison on YouCook2.</p>
        </div>
      </div>
    </div>

    <div class="content">
      <h3 class="title is-4">Reactive Interaction: Question Answering</h3>
      <p>In standard QA settings, ROMA maintains strong context understanding capabilities.</p>
      <div class="columns is-centered">
        <div class="column is-full-width">
          <img src="./static/case_turn.png" alt="Reactive QA Case" class="result-image" style="width: 100%;">
          <p class="teaser-caption has-text-centered"><strong>Figure: Reactive QA Case.</strong></p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Quantitative Results</h2>

    <h3 class="title is-4 results-subtitle">Proactive Tasks: Event-Driven Alert</h3>
    <div class="columns is-centered">
      <div class="column is-half has-text-centered">
        <img src="./static/alert1.png" alt="Alert Table 1" class="result-image" style="width: 100%;">
        <p class="table-caption"><strong>Table: Performance on QVHighlights & Charades-STA.</strong></p>
      </div>
      <div class="column is-half has-text-centered">
        <img src="./static/alert2.png" alt="Alert Table 2" class="result-image" style="width: 100%;">
        <p class="table-caption"><strong>Table: Single & Recurring Alert Performance.</strong></p>
      </div>
    </div>

    <h3 class="title is-4 results-subtitle">Proactive Tasks: Real-Time Narration</h3>
    <div class="columns is-centered">
      <div class="column is-10 has-text-centered">
        <img src="./static/narration.png" alt="Narration Table" class="result-image" style="width: 100%;">
        <p class="table-caption"><strong>Table: Streaming Narration on YouCook2 & OVO-Bench (SSR).</strong></p>
      </div>
    </div>

    <h3 class="title is-4 results-subtitle">Reactive Tasks: QA & Streaming Understanding</h3>
    
    <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">
        <img src="./static/ovo.jpg" alt="OVO Bench Table" class="result-image" style="width: 100%;">
        <p class="table-caption"><strong>Table: Reactive QA on OVO-Bench (Real-time Visual Perception & Backward Tracing).</strong></p>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">
        <img src="./static/streaming.jpg" alt="Streaming Bench Table" class="result-image" style="width: 100%;">
        <p class="table-caption"><strong>Table: Performance on StreamingBench.</strong></p>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-two-thirds has-text-centered">
        <img src="./static/omni.png" alt="Omni Bench Table" class="result-image" style="width: 100%;">
        <p class="table-caption"><strong>Table: Full-Modality QA on Video-MME & EgoSchema.</strong></p>
      </div>
    </div>

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre class="bibtex-box"><code>@article{roma2025,
  title={ROMA: Real-time Omni-Multimodal Assistant with Interactive Streaming Understanding},
  author={Anonymous Authors},
  journal={ACL Submission},
  year={2025}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>
        This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
        Template adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
      </p>
    </div>
  </div>
</footer>

</body>
</html>
